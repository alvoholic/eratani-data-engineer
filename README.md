# Eratani Data Pipeline - Agriculture Metrics Project

## Deskripsi Proyek
Proyek ini membangun sebuah pipeline end-to-end menggunakan **Apache Airflow** untuk orkestrasi, **dbt** untuk transformasi data, dan **PostgreSQL** sebagai data warehouse. Pipeline melakukan ingestion dari file CSV, membuat tabel staging, fact, dan menghasilkan tabel metrics harian (`agriculture_metrics_daily`) yang dapat digunakan untuk analisis performa pertanian.

---

## Tujuan
- Mengambil data mentah dari file `agriculture_dataset.csv` ke dalam Data Warehouse.
- Membersihkan dan memodelkan data menggunakan dbt.
- Menghasilkan metrik performa pertanian seperti Yield, Efisiensi Pupuk, dan Produktivitas Air.
- Menjalankan pipeline setiap hari pada pukul **06:00 UTC** menggunakan Airflow.
- Menyimpan hasil akhir di tabel `agriculture_metrics_daily`.

---

## Toolkit
- **Apache Airflow** â€“ untuk orkestrasi pipeline
- **dbt** â€“ untuk transformasi dan modelling data
- **PostgreSQL** â€“ sebagai Data Warehouse
- **Docker & Docker Compose** â€“ untuk menjalankan seluruh service dalam satu perintah
- **Python** (Pandas, psycopg2) â€“ untuk ingestion

---

## Struktur Project
```
eratani-data-engineer
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ eratani_pipeline.py                # Airflow DAG untuk ingest & load data
â”‚
â”œâ”€â”€ dbt_project/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/                       # Staging models (membersihkan & standarisasi data)
â”‚   â”‚   â”‚   â””â”€â”€ stg_agriculture.sql        # Model staging untuk tabel pertanian
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ fact/                          # Fact models (tabel fakta untuk analisis)
â”‚   â”‚   â”‚   â””â”€â”€ fact_farm_production.sql   # Model fact berisi agregasi produksi
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ metrics/                       # Metrics models (perhitungan KPI / indikator)
â”‚   â”‚   â”‚    â””â”€â”€ agriculture_metrics.sql   # Contoh metrik: yield, efisiensi air, dll.
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ sources.yml                    # Deklarasi sumber data untuk dbt (Postgres)
â”‚   â””â”€â”€ dbt_project.yml                    # Konfigurasi utama dbt project
â”‚  
â”œâ”€â”€ data/
â”‚   â””â”€â”€ agriculture_dataset.csv            # Raw CSV input untuk Airflow ingestion
â”‚
â”œâ”€â”€ docker-compose.yml                     # Orkestrasi Docker (Postgres, Airflow)
â”œâ”€â”€ requirements.txt                       # Dependency Python untuk Airflow & scripts
â”œâ”€â”€ Dockerfile                             # Custom image Airflow (opsional, jika digunakan)
â”œâ”€â”€ README.md                              # Dokumentasi project
â””â”€â”€ .gitignore                             # File/folder yang diabaikan Git
```

---

## Cara Menjalankan Project

### 1. Jalankan Docker
```bash
docker-compose up --build```
### 2. Akses Airflow UI
http://localhost:8080
Login default:
User: airflow
Password: airflow
3. Aktifkan dan jalankan DAG
Cari DAG bernama:
eratani_pipeline
ðŸ‘‰ Toggle ON
ðŸ‘‰ Klik â–¶ Run untuk eksekusi pertama
Pipeline otomatis berjalan setiap 06:00 UTC.
