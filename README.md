# Eratani Data Pipeline - Agriculture Metrics Project ðŸŒ¾

## ðŸ“Œ Deskripsi Proyek
Proyek ini membangun sebuah pipeline end-to-end menggunakan **Apache Airflow** untuk orkestrasi, **dbt** untuk transformasi data, dan **PostgreSQL** sebagai data warehouse. Pipeline melakukan ingestion dari file CSV, membuat tabel staging, fact, dan menghasilkan tabel metrics harian (`agriculture_metrics_daily`) yang dapat digunakan untuk analisis performa pertanian.

---

## ðŸŽ¯ Tujuan
- Mengambil data mentah dari file `agriculture_dataset.csv` ke dalam Data Warehouse.
- Membersihkan dan memodelkan data menggunakan dbt.
- Menghasilkan metrik performa pertanian seperti Yield, Efisiensi Pupuk, dan Produktivitas Air.
- Menjalankan pipeline setiap hari pada pukul **06:00 UTC** menggunakan Airflow.
- Menyimpan hasil akhir di tabel `agriculture_metrics_daily`.

---

## ðŸ§° Toolkit
- **Apache Airflow** â€“ untuk orkestrasi pipeline
- **dbt** â€“ untuk transformasi dan modelling data
- **PostgreSQL** â€“ sebagai Data Warehouse
- **Docker & Docker Compose** â€“ untuk menjalankan seluruh service dalam satu perintah
- **Python** (Pandas, psycopg2) â€“ untuk ingestion

---

## ðŸ“‚ Struktur Project
```
.
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ eratani_pipeline.py        # Airflow DAG
â”œâ”€â”€ dbt_project/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/               # Staging models
â”‚   â”‚   â”œâ”€â”€ fact/                  # Fact models
â”‚   â”‚   â””â”€â”€ metrics/               # Metrics models
â”‚   â””â”€â”€ dbt_project.yml
â”œâ”€â”€ data/
â”‚   â””â”€â”€ agriculture_dataset.csv    # Raw CSV input
â”œâ”€â”€ docker-compose.yml             # Container orchestration
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # Documentation
â””â”€â”€ .gitignore                     # Ignored files
```


---

## ðŸš€ Cara Menjalankan Project

### 1. Jalankan Docker
```bash
docker-compose up --build
2. Akses Airflow UI
http://localhost:8080
Login default:
User: airflow
Password: airflow
3. Aktifkan dan jalankan DAG
Cari DAG bernama:
eratani_pipeline
ðŸ‘‰ Toggle ON
ðŸ‘‰ Klik â–¶ Run untuk eksekusi pertama
Pipeline otomatis berjalan setiap 06:00 UTC.
